# RAG AI Chatbot

This is a **Retrieval-Augmented Generation (RAG) AI Chatbot** that combines **large language models (LLMs)**
It allows users to chat in real-time, upload files for context.

---
## ğŸ’¬  Demo ğŸ¥

https://github.com/user-attachments/assets/e0be246c-3467-4616-b279-c4bb21d76988

---
## âš¡ Features

- **RAG Pipeline**: Combines user queries with vector-based knowledge for contextual answers.  
- **Streaming Responses**: LLM output is streamed token-by-token.  
- **Chat History**: Users can create, switch, and delete chat sessions.  
- **File Uploads**: Supports TXT, PDF, CSV, and DOCX files to augment context.  
- **Vector Store Integration**: FAISS-based vector store for fast similarity search.  
- **Dockerized**: Both frontend and backend can run in containers.  

---


## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ src/ 
â”‚ â”‚ â”œâ”€â”€ api/v1/routes.py # API routes
â”‚ â”‚ â”œâ”€â”€ services/
â”‚ â”‚ â”‚ â”œâ”€â”€ llm.py # LLM wrappers & streaming
â”‚ â”‚ â”‚ â””â”€â”€ retrieval.py # Knowledge retrieval logic
â”‚ â”‚ â”œâ”€â”€ models/schema.py # Request/response validation
â”‚ â”‚ â”œâ”€â”€ db/vector_store.py # Vector store (FAISS) management
â”‚ â”‚ â””â”€â”€ config.py # API keys, model options, etc.
â”‚ â”œâ”€â”€ app.py # FastAPI entrypoint
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â””â”€â”€ pyproject.toml
â””â”€â”€ frontend/
â”œâ”€â”€ app.py # Streamlit main app
â”œâ”€â”€ services/
â”‚ â”œâ”€â”€ chat_service.py # Chat session management
â”‚ â””â”€â”€ api_client.py # Backend API client
â”œâ”€â”€ Dockerfile
â””â”€â”€ pyproject.toml
